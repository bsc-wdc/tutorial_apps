{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans with Redis\n",
    "\n",
    "KMeans is machine-learning algorithm (NP-hard), popularly employed for cluster analysis in data mining, and interesting for benchmarking and performance evaluation. \n",
    "\n",
    "The objective of the Kmeans algorithm to group a set of multidimensional points into a predefined number of clusters, in which each point belongs to the closest cluster (with the nearest mean distance), in an iterative process.\n",
    "\n",
    "This implementation uses Redis to store the input points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data model is used to define the objects that will be used in the storage system (Redis).\n",
    "\n",
    "To this end, it is necessary to implement the user defined classes **overriding the StorageObject** class from the storage API.\n",
    "\n",
    "*--> In Jupyter notebook, the data model has to be defined into a separate file in order to be imported in the workers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile data_model.py\n",
    "\n",
    "from storage.storage_object import StorageObject\n",
    "\n",
    "class PSCO(StorageObject):\n",
    "    def __init__(self, matrix=\"Content\"):\n",
    "        super(PSCO, self).__init__()\n",
    "        self.matrix = matrix\n",
    "\n",
    "    def get_matrix(self):\n",
    "        return self.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And import it to be used in the master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import PSCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start PyCOMPSs\n",
    "\n",
    "First, import the PyCOMPSs library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycompss.interactive as ipycompss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the COMPSs runtime defining:\n",
    "\n",
    "* the storage implementation with the **storage_impl** parameter ('redis' specifies the built-in Redis API)\n",
    "* the storage configuration file with the **storage_conf** parameter (which contains the nodes - one per line - that belong to the infrastructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipycompss.start(storage_impl='redis', storage_conf=os.getcwd() + \"/storage_conf.txt\", graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue as a normal PyCOMPSs application..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompss.api.task import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random(numV, dim, seed):\n",
    "    np.random.seed(seed)\n",
    "    c = [np.random.uniform(-3.5, 3.5, dim)]\n",
    "    while len(c) < numV:\n",
    "        p = np.random.uniform(-3.5, 3.5, dim)\n",
    "        distance = [np.linalg.norm(p-i) for i in c]\n",
    "        if min(distance) > 2:\n",
    "            c.append(p)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some functions or tasks, the user can use the classes defined in the data model, and since they override **StorageObject** class, they contain the storage API defined functions, such as **make_persistent**.\n",
    "\n",
    "* **make_persistent** forces the object to be stored in the underlying storage (Redis), and from that point, PyCOMPSs will use just the object identifier among nodes. The workers will retrieve automatically to the objects through the storage API\n",
    "\n",
    "* Also, since it is an object, it is possible to invoke the user defined methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@task(returns=PSCO)  # Not a task for plotting\n",
    "def genFragment(numV, K, c, dim, mode='gauss'):\n",
    "    if mode == \"gauss\":\n",
    "        n = int(float(numV) / K)\n",
    "        r = numV % K\n",
    "        data = []\n",
    "        for k in range(K):\n",
    "            s = np.random.uniform(0.05, 0.75)\n",
    "            for i in range(n+r):\n",
    "                d = np.array([np.random.normal(c[k][j], s) for j in range(dim)])\n",
    "                data.append(d)\n",
    "        mat = np.array(data)[:numV]\n",
    "    else:\n",
    "        mat = [np.random.random(dim) for _ in range(numV)]\n",
    "    fragment = PSCO(mat)\n",
    "    fragment.make_persistent()\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks which receive a storage object can use them as normal objects (e.g. XP in **cluster_points_partial** and **partial_sum**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(returns=dict)\n",
    "def cluster_points_partial(XP, mu, ind):\n",
    "    dic = {}\n",
    "    for x in enumerate(XP.get_matrix()):\n",
    "        bestmukey = min([(i[0], np.linalg.norm(x[1] - mu[i[0]])) for i in enumerate(mu)], key=lambda t: t[1])[0]\n",
    "        if bestmukey not in dic:\n",
    "            dic[bestmukey] = [x[0] + ind]\n",
    "        else:\n",
    "            dic[bestmukey].append(x[0] + ind)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(returns=dict)\n",
    "def partial_sum(XP, clusters, ind):\n",
    "    p = [(i, [(XP.get_matrix()[j - ind]) for j in clusters[i]]) for i in clusters]\n",
    "    dic = {}\n",
    "    for i, l in p:\n",
    "        dic[i] = (len(l), np.sum(l, axis=0))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centers reduction task and merging function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(returns=dict, priority=True)\n",
    "def reduceCentersTask(a, b):\n",
    "    for key in b:\n",
    "        if key not in a:\n",
    "            a[key] = b[key]\n",
    "        else:\n",
    "            a[key] = (a[key][0] + b[key][0], a[key][1] + b[key][1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeReduce(function, data):\n",
    "    from collections import deque\n",
    "    q = deque(list(range(len(data))))\n",
    "    while len(q):\n",
    "        x = q.popleft()\n",
    "        if len(q):\n",
    "            y = q.popleft()\n",
    "            data[x] = function(data[x], data[y])\n",
    "            q.append(x)\n",
    "        else:\n",
    "            return data[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence check function:\n",
    "\n",
    "* When *maxIterations* is reached\n",
    "* Distance between the old centers and the new ones is lower than *epsilon*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(mu, oldmu, epsilon, iter, maxIterations):\n",
    "    print(\"iter: \" + str(iter))\n",
    "    print(\"maxIterations: \" + str(maxIterations))\n",
    "    if oldmu != []:\n",
    "        if iter < maxIterations:\n",
    "            aux = [np.linalg.norm(oldmu[i] - mu[i]) for i in range(len(mu))]\n",
    "            distance = sum(aux)\n",
    "            if distance < epsilon * epsilon:\n",
    "                print(\"Distance_T: \" + str(distance))\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Distance_F: \" + str(distance))\n",
    "                return False\n",
    "        else:\n",
    "            # Reached the max amount of iterations\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting function:\n",
    "\n",
    "* Represent a 2D or 3D picture of the centers and points (coloured by cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotKMEANS(dim, mu, clusters, data):\n",
    "    import pylab as plt\n",
    "    colors = ['b','g','r','c','m','y','k']\n",
    "    if dim == 2:\n",
    "        from matplotlib.patches import Circle\n",
    "        from matplotlib.collections import PatchCollection\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        patches = []\n",
    "        pcolors = []\n",
    "        for i in range(len(clusters)):\n",
    "            for key in clusters[i].keys():\n",
    "                d = clusters[i][key]\n",
    "                for j in d:\n",
    "                    j = j - i * len(data[0].get_matrix())\n",
    "                    C = Circle((data[i].get_matrix()[j][0], data[i].get_matrix()[j][1]), .05)\n",
    "                    pcolors.append(colors[key])\n",
    "                    patches.append(C)\n",
    "        collection = PatchCollection(patches)\n",
    "        collection.set_facecolor(pcolors)\n",
    "        ax.add_collection(collection)\n",
    "        x, y = zip(*mu)\n",
    "        plt.plot(x, y, '*', c='y', markersize=20)\n",
    "        plt.autoscale(enable=True, axis='both', tight=False)\n",
    "        plt.show()\n",
    "    elif dim == 3:\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(len(clusters)):\n",
    "            for key in clusters[i].keys():\n",
    "                d = clusters[i][key]\n",
    "                for j in d:\n",
    "                    j = j - i * len(data[0].get_matrix())\n",
    "                    ax.scatter(data[i].get_matrix()[j][0], data[i].get_matrix()[j][1], data[i].get_matrix()[j][2], 'o', c=colors[key])\n",
    "        x, y, z = zip(*mu)\n",
    "        for i in range(len(mu)):\n",
    "            ax.scatter(x[i], y[i], z[i], s=80, c='y', marker='D')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No representable dim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN\n",
    "\n",
    "Parameters (that can be configured in the following cell):\n",
    "\n",
    "* **numV**: number of vectors (default: 10.000)                                                           \n",
    "* **dim**: dimension of the points (default: 2)\n",
    "* **k**: number of centers (default: 4)\n",
    "* **numFrag**: number of fragments (default: 16)\n",
    "* **epsilon**: convergence condition (default: 1e-10)\n",
    "* **maxIterations**: Maximum number of iterations (default: 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycompss.api.api import compss_wait_on\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "numV = 10000       # Vectors ----- with 1000 it is feasible to see the evolution across iterations\n",
    "dim = 2            # Dimensions\n",
    "k = 4              # Centers\n",
    "numFrag = 16       # Fragments\n",
    "epsilon = 1e-10    # Convergence condition\n",
    "maxIterations = 20 # Max number of iterations\n",
    "\n",
    "size = int(numV / numFrag)\n",
    "startTime = time.time()\n",
    "cloudCenters = init_random(k, dim, 8) # centers to create data groups\n",
    "X = [genFragment(size, k, cloudCenters, dim, mode='gauss') for _ in range(numFrag)]\n",
    "\n",
    "mu = init_random(k, dim, 7) # First centers\n",
    "oldmu = []\n",
    "n = 0\n",
    "startTime = time.time()\n",
    "while not has_converged(mu, oldmu, epsilon, n, maxIterations):\n",
    "    oldmu = mu\n",
    "    clusters = [cluster_points_partial(X[f], mu, f * size) for f in range(numFrag)]\n",
    "    partialResult = [partial_sum(X[f], clusters[f], f * size) for f in range(numFrag)]\n",
    "    mu = mergeReduce(reduceCentersTask, partialResult)\n",
    "    mu = compss_wait_on(mu)\n",
    "    mu = [mu[c][1] / mu[c][0] for c in mu]\n",
    "    while len(mu) < k:\n",
    "        # Add new random center if one of the centers has no points.\n",
    "        indP = np.random.randint(0, size)\n",
    "        indF = np.random.randint(0, numFrag)\n",
    "        mu.append(X[indF].get_matrix()[indP])\n",
    "    n += 1\n",
    "\n",
    "clusters = compss_wait_on(clusters)\n",
    "    \n",
    "print(\"-----------------------------\")\n",
    "print(\"Kmeans Time {} (s)\".format(time.time() - startTime))\n",
    "print(\"-----------------------------\")\n",
    "print(\"Result:\")\n",
    "print(\"Iterations: \", n)\n",
    "print(\"Centers: \", mu)\n",
    "\n",
    "plotKMEANS(dim, mu, clusters, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the COMPSs runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipycompss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
